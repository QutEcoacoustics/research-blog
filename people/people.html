---
layout: default
title: Ecosounds | People
---

<div id="people">
    <h1>People</h1>

    <ul class="media-list" id="people-list">
        <li class="media">
            <span class="pull-left">
                <img class="media-object" src="../images/paul_roe.jpg" alt="Paul Roe">
            </span>

            <div class="media-body">
                <h4 class="media-heading">Prof. Paul Roe</h4>
                Paul Roe is a full professor in the Science and Engineering Faculty at QUT, in Brisbane Australia, where
                he leads the Bioacoustic Research Lab. He has published over 80 papers and received over $4 M in
                competitive research funding. His research is focused on smart tools which enable new forms and scales
                of research, particularly in the area of distributed computing.
            </div>
        </li>
        <li class="media">
            <span class="pull-left">
                <img class="media-object" src="../images/Dr-Jinglan-Zhang.png" alt="Dr. Jinglan Zhang">
            </span>

            <div class="media-body">
                <h4 class="media-heading">Dr. Jinglan Zhang</h4>
                Dr. Jinglan Zhang is a senior lecturer in Queensland University of Technology. She received her PhD in
                Information Technology in 2003 from Queensland University of Technology. Dr. Zhang has worked as
                an Engineer in Computer Aided Design and Computer Aided Engineering for 8 years and a researcher
                in Information Technology for more than 10 years. She has published more than 40 refereed research
                papers and jointly received about $1M in research funding. Her broad research area falls in Artificial
                Intelligence and Computer Software. In particular, her research interests include Visual and Acoustic
                Information (Graphics, Images, and Sound) Processing and Retrieval, Data Mining and Computer Human
                Interaction. The application areas include environmental monitoring and web intelligence. She has
                successfully supervised two PhD and one Master by Research students to completion.
            </div>
        </li>
        <li class="media">
            <span class="pull-left">
                <img class="media-object" src="../images/mike_towsey.jpg" alt="Dr. Michael Towsey">
            </span>

            <div class="media-body">
                <h4 class="media-heading">Dr. Michael Towsey</h4>
                Dr. Michael Towsey has held research positions at QUT since 1997. He uses machine learning methods to
                solve biological problems. These have ranged from the sublime (analysis of bird song) to the ridiculous
                (analysis of milk yield in cow herds) with some bioinformatics in between! Michael is currently in the
                Bioacoustics Research Group within the School of Electrical Engineering and Computer Science at QUT. He
                works on the ‘big data’ problems associated with long duration recordings of the environment, in
                particular, building recognizers for species of interest, extracting acoustic indices to aid navigation
                and visualisation.
            </div>
        </li>
        <li class="media">
            <span class="pull-left">
                <img class="media-object" src="../images/Jess_bio_QUT.jpg" alt="Jessie Cappadonna">
            </span>

            <div class="media-body">
                <h4 class="media-heading">Jessie Cappadonna</h4>
				Throughout her career, Jessie Cappadonna, has been passionate about avian ecology and public engagement. 
				In recent years, this led her to contribute on a wide variety of projects with the U.S. Geological Survey (Hawai`i), 
				the U.S. Fish and Wildlife Service (Hawai`i), Point Blue Conservation Science (California), and the Cornell Lab of 
				Ornithology (New York). Upon return to Australia, Jessie worked with University of Queensland's Environmental Decisions 
				Group, and also became heavily involved with the Australian Citizen Science Association. Now she is embarking on a PhD 
				investing the use of bioacoustics in citizen science projects at the Queensland University of Technology.
            </div>
        </li>
        <li class="media">
            <span class="pull-left">
                <img class="media-object" src="../images/mark1.jpg" alt="Mark Cottman-Fields">
            </span>

            <div class="media-body">
                <h4 class="media-heading">Mark Cottman-Fields</h4>
                Mark Cottman-Fields is a PhD student. His research is titled Engaging Expert Birders to Analyse
                Bioacoustic Data. The recordings that the research group obtains from the field are used to prototype
                website interfaces for birders to listen and identify bird vocalisations. In order to extend birders’
                physical activities online, allowing them to make use of existing expertise, his work includes
                investigating
                the established culture and practice of birders. This research will provide straight-forward and
                engaging
                online activities that build on and make use of physical experiences. The online tools produced form
                this
                work will support the creation of large-scale observational data for ecologists.
            </div>
        </li>
        <li class="media">
            <span class="pull-left">
                <img class="media-object" src="../images/xueyan.png" alt="Xueyan Dong">
            </span>

            <div class="media-body">
                <h4 class="media-heading">Xueyan Dong</h4>
                Xueyan Dong is a PhD student at QUT. Her research is focused on Content-based acoustic event retrieval
                on
                field audio data.
            </div>
        </li>
        <li class="media">
            <span class="pull-left">
                <img class="media-object" src="../images/phil.jpg" alt="Phil Eichinski">
            </span>

            <div class="media-body">
                <h4 class="media-heading">Phil Eichinski</h4>
                Combining automated and non-automated methods of acoustic analysis for bird species richness surveys.
                Phil's research will explore ways of using automated acoustic analysis to determine rich and diverse
                subsets of a long recording. This will speed up the process of a manual species richness survey
                conducted by a human, as they will need to listen to less audio to observe all the species present.
            </div>
        </li>
        <li class="media">
            <span class="pull-left">
               <img class="media-object" src="../images/Yvonne.jpg" alt="Yvonne Phillips">
            </span>

            <div class="media-body">
                <h4 class="media-heading">Yvonne Phillips</h4>
                Yvonne Phillips is a PhD student at QUT.  She is interested in spatial and temporal heterogeneity 
                of sound within ecosystems and at ecosystem boundaries.
            </div>
        </li>
        <li class="media">
            <span class="pull-left">
                <img class="media-object" src="../images/Mangalam.jpg" alt="Mangalam Sankupellay">
            </span>

            <div class="media-body">
                <h4 class="media-heading">Dr Mangalam Sankupellay</h4>
               Dr Mangalam Sankupellay is a Research associate within the Bioacoustics Research Group within the School of 
               Electrical Engineering and Computer Science at QUT. She uses machine learning techniques to analyse bird song.
            </div>
        </li>
        <li class="media">
            <span class="pull-left">
                <img class="media-object" src="../images/Ant.jpg" alt="Anthony Truskinger">
            </span>

            <div class="media-body">
                <h4 class="media-heading">Anthony Truskinger</h4>
                Anthony Truskinger is a PhD student nearing the end of his candidature. His PhD, entitled Semi-Automated
                Annotation of Environmental Acoustic Recordings, is focused on assisting the citizen scientists that
                contribute useful information in online bioacoustic analysis environments. Anthony is also a research
                assistant working for the bioacoustics research group. He supports other researchers within the group by
                managing data, running large scale analyses on large compute resources, and by developing professional
                bioacoustic analysis software for the web.
            </div>
        </li>
        <li class="media">
            <span class="pull-left">
                <img class="media-object" src="../images/Dezmond-Wells.png" alt="Dezmond Wells">
            </span>

            <div class="media-body">
                <h4 class="media-heading">Dezmond Wells</h4>
                Dezmond Wells is a Research Masters student at QUT. His thesis is entitled: How can the affects of
                habitat attenuation on acoustic sensors recording avian species be used to determine abundance in a
                two-hectare ecological sample.
            </div>
        </li>
        <li class="media">
            <span class="pull-left">
                <img class="media-object" src="../images/jason.jpg" alt="Jason Wimmer">
            </span>

            <div class="media-body">
                <h4 class="media-heading">Jason Wimmer</h4>
                Jason Wimmer completed his PhD with QUT researching the role of acoustic sensors for monitoring
                biodiversity.
                His thesis is entitled: Acoustic Sensing: Roles and Applications in Monitoring Avian Biodiversity.
            </div>
        </li>
        <li class="media">
            <span class="pull-left">
                <img class="media-object" src="../images/jie.jpg" alt="Jie Xie">
            </span>

            <div class="media-body">
                <h4 class="media-heading">Jie Xie</h4>
                Jie is a PhD student at QUT. His thesis is entitled: Acoustic Monitoring by Frog Call Analysis.
            </div>
        </li>
        <li class="media">
            <span class="pull-left">
                <img class="media-object" src="../images/Liang.jpg" alt="Liang Zhang">
            </span>

            <div class="media-body">
                <h4 class="media-heading">Liang Zhang</h4>
                Liang Zhang is a PhD student in the Science and Engineering Faculty at QUT. His research interest is in
                acoustic regime in long duration audio recording.
            </div>
        </li>
    </ul>
</div>

<div id="people">
    <h1>Past Members</h1>
    
    <ul class="media-list" id="people-list">
        <li class="media">
            <span class="pull-left">
                <img class="media-object" src="../images/Shufei.jpg" alt="Shufei Duan">
            </span>

            <div class="media-body">
                <h4 class="media-heading">Shufei Duan</h4>
                Shufei Duan was a PhD student at QUT. Her thesis is entitled: Automated Species Recognition in
                Bioacoustic Recordings.
            </div>
        </li>
        <li class="media">
            <span class="pull-left">
                <img class="media-object" src="../images/meriem.jpg" alt="Meriem Ferroudj">
            </span>

            <div class="media-body">
                <h4 class="media-heading">Meriem Ferroudj</h4>
                Meriem Ferroudj was a Masters student at QUT. Her thesis is entitled: Automated rain classification in
                environmental sound.
            </div>
        </li>
        <li class="media">
            <span class="pull-left">
                <img class="media-object" src="../images/mark_vandeberg.jpg" alt="Mark Vandeberg">
            </span>

            <div class="media-body">
                <h4 class="media-heading">Mark Vandeberg</h4>
                Mark Vandeberg was a masters student at QUT. His thesis is entitled: Bringing Big Data to Many People via Large Display
            </div>
        </li>
    </ul>
</div>
